{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c467cdbc",
   "metadata": {},
   "source": [
    "## Отчет по штатному расписанию <img style=\"float: right;\" src=\"../00_system/VTB.png\">\n",
    "\n",
    "Отражение ситуации на конец отчетного месяца по сотрудникам: штатная численность, фактическая численность, новые и ушедшие сотрудники, вакансии\n",
    "\n",
    "> **Частота обновления:**<br>\n",
    "> * ежемесячно, ~ до 5 числа следующим за отчетным <br>\n",
    "\n",
    "> **Ответственные:** <br> \n",
    "> * за разработку: ФИО <name@.ru>, ФИО <name@.ru> <br> \n",
    "> * за данные: ФИО <name@.ru> <br>\n",
    "   \n",
    "> **Ссылки на отчеты:** <br>\n",
    "> * дашборд `Excel` - `\\\\*\\Штатное расписание ЦАП`\n",
    "> * дашборд `Qlik` -  https://.ru\n",
    "\n",
    "> **Ссылки на исходные файлы:** <br>\n",
    "> * справочники: `\\\\*\\dics` <br>\n",
    "> * исходные файлы: `\\\\*\\raw`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5fc1a31",
   "metadata": {},
   "source": [
    "### Импортируем библиотеки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "738bd16a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:90% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#увеличиваем рабочую область\n",
    "from IPython.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:90% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e60a662d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd #работа с таблицами\n",
    "import os #для работы с папками\n",
    "pd.options.mode.chained_assignment = None #Отключение предупреждения Pandas \"SettingWithCopyWarning:A value is trying to be set on a copy of a slice from a DataFrame\"\n",
    "import datetime #для сохранения в имени файла даты и времени сохранения\n",
    "import numpy as np\n",
    "import msoffcrypto #для работы по расшифровке книги по паролю\n",
    "import io #для работы по расшифровке книги по паролю"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f078d687",
   "metadata": {},
   "source": [
    "### Функции для работы с файлами"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c52b5c5",
   "metadata": {},
   "source": [
    "#### Функция для открытия файлов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1611a333",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Функция для открытия файла и передачи для дальнейшей обработки\n",
    "#  Переменные на вход:\n",
    "#   - file_ - путь к файлу\n",
    "#   - file_mask - маска наименовании файла\n",
    "#   - need_split - требуется ли разделение названия файла, используется по файлам штатной численности, по умолчанию False\n",
    "#   - sheet_name_ - None если все листы, 0 - первый лист, остальное - если конкретное\n",
    "#   - header_ - строка с заголовками\n",
    "#   - skip_rows - пропуск строк сверху\n",
    "#   - usecols_ - определенные столбцы к загрузке\n",
    "#   - password_ - пароль к книге Excel при необходимости\n",
    "#\n",
    "def open_file (file_, file_mask, need_split = False, sheet_name_ = None, header_ = 0, skip_rows = None, usecols_ = None, password_ = None):\n",
    "    #определение, файл ли это\n",
    "    is_file = os.path.isfile(file_)\n",
    "    #определить расширение файла\n",
    "    file_ext = os.path.splitext(file_)[1].lower()\n",
    "    #определяем движок в зависимости от типа файла\n",
    "    engine_ = 'xlrd' if file_ext == '.xls' else 'openpyxl'\n",
    "    #определяем наименование файла\n",
    "    file_name = os.path.basename(file_)\n",
    "    #если это файл, движок определен и название файла попадает под маску - осуществляем перебор\n",
    "    if is_file and file_mask in file_name:\n",
    "        #открываем файл\n",
    "        with open(file_,'rb') as f:\n",
    "            #если у нас Excel файл с паролем, то перед открытием мы его снимаем, password_ должен быть подан на вход\n",
    "            if password_ is not None:\n",
    "                file_ = io.BytesIO()\n",
    "                file = msoffcrypto.OfficeFile(f)\n",
    "                file.load_key(password = password_)  # Use password\n",
    "                file.decrypt(file_)\n",
    "            else:\n",
    "                file_ = f #если\n",
    "            #открываем книгу Excel\n",
    "            try:\n",
    "                df = pd.read_excel(file_, \n",
    "                    sheet_name= sheet_name_,\n",
    "                    engine = engine_, \n",
    "                    header= header_,\n",
    "                    skiprows = skip_rows,\n",
    "                    usecols = usecols_,\n",
    "                    index_col = None)\n",
    "                #файл источник\n",
    "                df['Дата_отчета'] = '01-' + file_name.split(\"_\")[2][:-5] if need_split else file_name\n",
    "                #отбивка об обработке\n",
    "                print(f\"Обработан файл - '{file_name}\")\n",
    "                #возвращаем датафрем\n",
    "                return df\n",
    "            except Exception as e:\n",
    "                print(f\"Не удалось обработать файл - '{file_name}', с ошибкой - {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08f723ed",
   "metadata": {},
   "source": [
    "#### Функция для сборки файлов по штатной численности"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6b9c6af7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def merging_staff_files(dir_in):\n",
    "    #наименование функции или блока для отработки ошибок\n",
    "    unit = 'merging_staff_files'\n",
    "    #dir_in - расположение файлов прогнозов\n",
    "    #dir_out - куда сохраняем итоговые файл\n",
    "    #file_name - наименование итогового файла.\n",
    "    try:\n",
    "        #загружаемые столбцы\n",
    "        heads = ['ID Штатной единицы','Unnamed: 5','Unnamed: 6','Unnamed: 7','Unnamed: 8',\n",
    "                 'Должность','Штатная численность','Фактическая численность','ФИО','Таб. №','Город, ФН','Признак ШЕ',\n",
    "                 'Дата начала действия признака','Дата окончания отпуска по уходу за ребенком','Дата увольнения',\n",
    "                 'Примечание']\n",
    "        #создаем итоговую таблицу\n",
    "        df_total = pd.DataFrame()\n",
    "        #перебираем файлы в папке\n",
    "        for entry in os.scandir(dir_in): #перебираем все файлы в папке\n",
    "            #открываем каждый файл в папке\n",
    "            df = open_file (entry.path, 'staff_regions', need_split = True, sheet_name_ = 0, skip_rows = 5, usecols_ = heads)\n",
    "            #продолжить, если таблица пустая\n",
    "            if df is not None:\n",
    "                #временная таблица\n",
    "                df_temp = pd.DataFrame()\n",
    "                #удаляем две лишние строки т.к. заголовок был многоуровневый\n",
    "                df_temp = df.iloc[2:,:]\n",
    "                #переименование столбцов\n",
    "                df_temp.columns = ['id','Управление','ЦАП','ПАП','Отдел','Должность','ШЧ','ФЧ','ФИО','ТН','Город','Признак_ШЕ','Дата_начала_действия_признака','Дата_окончания_отпуска_по_уходу_за_ребенком','Дата_увольнения','Примечание','Дата_отчета']\n",
    "                #переносим итоговый результат в итоговую таблицу\n",
    "                df_total = pd.concat([df_total, df_temp])\n",
    "                #очищаем временную таблицу\n",
    "                df_temp = None\n",
    "            #очищаем df\n",
    "            df = None\n",
    "        #возвращаем обработанные данные\n",
    "        return df_total\n",
    "    except Exception as e:\n",
    "        err_descr (unit, e)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "162948a8",
   "metadata": {},
   "source": [
    "#### Функция для сборки файлов по движению персонала"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "52207f3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def merging_staff_moving_files(dir_in):\n",
    "    #наименование функции или блока для отработки ошибок\n",
    "    unit = 'merging_staff_moving_files'\n",
    "    #dir_in - расположение файлов прогнозов\n",
    "    #dir_out - куда сохраняем итоговые файл\n",
    "    #file_name - наименование итогового файла.\n",
    "    try:\n",
    "        #загружаемые столбцы\n",
    "        heads = ['Таб. №','Дата приема']\n",
    "        #создаем итоговую таблицу\n",
    "        df_total = pd.DataFrame()\n",
    "        for entry in os.scandir(dir_in): #перебираем все файлы в папке\n",
    "            #открываем каждый файл в папке\n",
    "            df = open_file (entry.path, 'Отчет по движению персонала', need_split = False, sheet_name_ = 0, skip_rows = 3, usecols_ = heads, password_ = '2023')\n",
    "            #продолжить, если таблица пустая\n",
    "            if df is not None:\n",
    "                #временная таблица\n",
    "                df_temp = pd.DataFrame()\n",
    "                #удаляем две лишние строки т.к. заголовок был многоуровневый\n",
    "                df_temp = df.iloc[2:,:]\n",
    "                #переименование столбцов\n",
    "                #df_temp.columns = ['id','Управление','ЦАП','ПАП','Отдел','Должность','ШЧ','ФЧ','ФИО','ТН','Город','Признак_ШЕ','Дата_начала_действия_признака','Дата_окончания_отпуска_по_уходу_за_ребенком','Дата_увольнения','Примечание','Дата_отчета']\n",
    "                #переносим итоговый результат в итоговую таблицу\n",
    "                df_total = pd.concat([df_total, df_temp])\n",
    "                #очищаем временную таблицу\n",
    "                df_temp = None\n",
    "        #очищаем df\n",
    "        df = None\n",
    "        #возвращаем обработанные данные\n",
    "        return df_total\n",
    "    except Exception as e:\n",
    "        err_descr (unit, e)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eae1c0cc",
   "metadata": {},
   "source": [
    "#### Функция для возвращения текста ошибки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2db18c82",
   "metadata": {},
   "outputs": [],
   "source": [
    "def err_descr(unit_, exception_text):\n",
    "    print(f\"Ошибка: блок/функция '{unit_}', {exception_text}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9370138f",
   "metadata": {},
   "source": [
    "#### Функция для возвращения успешного статуса"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6dc8fc42",
   "metadata": {},
   "outputs": [],
   "source": [
    "def if_success(unit_):\n",
    "    print(f\"Выполнено: блок/функция '{unit_}'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e3cd87c",
   "metadata": {},
   "source": [
    "### Предобработка данных"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd749e53",
   "metadata": {},
   "source": [
    "#### Загрузка данных\n",
    "Объединение исходных данных в одну таблицу"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a802fd81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Обработан файл - 'staff_regions_01-2022.xlsm\n",
      "Обработан файл - 'staff_regions_01-2023.xlsm\n",
      "Обработан файл - 'staff_regions_02-2022.xlsm\n",
      "Обработан файл - 'staff_regions_02-2023.xlsm\n",
      "Обработан файл - 'staff_regions_03-2022.xlsm\n",
      "Обработан файл - 'staff_regions_03-2023.xlsm\n",
      "Обработан файл - 'staff_regions_04-2022.xlsm\n",
      "Обработан файл - 'staff_regions_04-2023.xlsx\n",
      "Обработан файл - 'staff_regions_05-2022.xlsm\n",
      "Обработан файл - 'staff_regions_06-2022.xlsm\n",
      "Обработан файл - 'staff_regions_07-2022.xlsm\n",
      "Обработан файл - 'staff_regions_08-2022.xlsm\n",
      "Обработан файл - 'staff_regions_09-2022.xlsm\n",
      "Обработан файл - 'staff_regions_10-2022.xlsm\n",
      "Обработан файл - 'staff_regions_11-2022.xlsm\n",
      "Обработан файл - 'staff_regions_12-2022.xlsm\n"
     ]
    }
   ],
   "source": [
    "#Местоположение загрузочных файлов\n",
    "file_strg = r'\\\\*\\Данные'\n",
    "#Объединение всех файлов в папке в одну таблицу\n",
    "df_staff = merging_staff_files (file_strg + \"\\\\raw\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b621670f",
   "metadata": {},
   "source": [
    "Объединение данных по уволенным сотрудникам в одну таблицу"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3a085ce8",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# ! отключил т.к. уволенные проверяются сверкой ТН из предыдущего месяца в текущем\n",
    "#file_strg_m = r'\\\\*\\Движение персонала ЦАП'\n",
    "#df_staff_m = merging_staff_moving_files (file_strg_m + \"\\\\2023\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af590b3e",
   "metadata": {},
   "source": [
    "### Предварительная обработка"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d246dcaa",
   "metadata": {},
   "source": [
    "#### Временная таблица для обработки\n",
    "Создаем временную таблицу для дальнейшей обработки данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "61fe0c67",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cоздаем временную таблицу для обработки\n",
    "df_t = df_staff.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b266ddbd",
   "metadata": {},
   "source": [
    "#### Дополнительные столбцы по статичному меппингу\n",
    "Накладываем меппинг, который находится в папках со справочниками "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bfbabf45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Обработан файл - 'dics_set.xlsx\n",
      "Выполнено: блок/функция 'Дополнительные столбцы по статичному меппингу'\n"
     ]
    }
   ],
   "source": [
    "#наименование функции или блока для отработки ошибок\n",
    "unit = 'Дополнительные столбцы по статичному меппингу'\n",
    "try:\n",
    "    #открываем файл меппинга\n",
    "    df_mapping = open_file (file_strg + '\\\\dics\\dics_set.xlsx', 'dics', False)\n",
    "\n",
    "    #----------------------------------------------------------------------------------------------\n",
    "    # 1. Накладываем категории должностей\n",
    "    df_t = df_t.merge(df_mapping['positions_cat'], on = 'Должность', how = 'left')\n",
    "    #проверка на отсутствующие аналитики\n",
    "    #--посчитаем количество строк с отсутствующими аналитиками\n",
    "    check_location = df_t.query(\"Категория_должности.isnull()\").shape[0]\n",
    "    #--если есть ненайденные, то вывод строк, которые не нашлись в меппинге\n",
    "    if check_location > 0:\n",
    "        print('Не найдены следующие аналитики по категориям должностей', display(df_t.query(\"Категория_должности.isnull()\")))\n",
    "\n",
    "    #----------------------------------------------------------------------------------------------\n",
    "    # 2. Накладываем ПАП-ы и ЦАП-ы отталкиваясь от ПАП\n",
    "    #--для начала объединим столбец ПАП и ЦАП т.к. ПАП не везде заполнен, если ПАП пустой, заполняем из ЦАП\n",
    "    df_t.loc[df_t['ПАП'].isnull(),'ПАП'] = df_t.loc[:,'ЦАП']\n",
    "    #--применяем меппинг по локациям\n",
    "    df_t = df_t.merge(df_mapping['locations'], left_on = 'ПАП', right_on = 'ПАП_полный', how = 'left')\n",
    "    #--проверка на отсутствующие аналитики\n",
    "    #--посчитаем количество строк с отсутствующими аналитиками\n",
    "    check_location = df_t.query(\"ПАП_полный.isnull()\").shape[0]\n",
    "    #--если есть ненайденные, то вывод строк, которые не нашлись в меппинге\n",
    "    if check_location > 0:\n",
    "        print('Не найдены следующие аналитики по определению ПАП', display(df_t.query(\"ПАП_полный.isnull()\")))\n",
    "\n",
    "    #----------------------------------------------------------------------------------------------\n",
    "    # 3. Накладываем корректировки по техническим вакансиям\n",
    "    df_t = df_t.merge(df_mapping['corr_tech'], on = 'id', how = 'left')\n",
    "    #--добавляем в столбец начальной даты, где не было заполнено, дату минимальную для нашего отчета 2021-01-01, чтобы корректно определять диапазон, когда ТН был техническим\n",
    "    df_t.loc[df_t.tech_date_end.notnull()&df_t.tech_date_st.isnull(),'tech_date_st'] = datetime.date(2021,1,1)\n",
    "    #----------------------------------------------------------------------------------------------\n",
    "    # Конвертируем столбцы с датами в формат дат для корректного сравнения\n",
    "    #--столбец Дата_отчета, месяца из наименования файлов, конвертируем в формат, использующийся во всей таблице\n",
    "    df_t[df_t.columns[16]] = pd.to_datetime(df_t[df_t.columns[16]], format = \"%d-%m-%Y\")\n",
    "    #--меняем столбцы с датами на единый формат даты\n",
    "    cols_d = np.r_[12:15,21:23]\n",
    "    df_t[df_t.columns[cols_d]] = df_t.loc[:,df_t.columns[cols_d]].apply(pd.to_datetime, format = \"%d.%m.%Y\")\n",
    "    #статус по завершению обработки блока/функции\n",
    "    if_success(unit)\n",
    "except Exception as e:\n",
    "    err_descr (unit, e)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "593d9b69",
   "metadata": {},
   "source": [
    "#### Дополнительные столбцы по условиям таблицы\n",
    "Создаем столбцы с дополнительными признаками"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "63994f5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Выполнено: блок/функция 'Дополнительные столбцы по статичному меппингу'\n"
     ]
    }
   ],
   "source": [
    "#наименование функции или блока для отработки ошибок\n",
    "unit = 'Дополнительные столбцы по статичному меппингу'\n",
    "try:\n",
    "    #Вакансия\n",
    "    df_t.loc[df_t['Признак_ШЕ'].str.contains('ВАК', na = False),'Ставка_вак'] = 1\n",
    "    #Декретная ставка\n",
    "    df_t.loc[df_t['Признак_ШЕ'].str.contains('ДЕК', na = False),'Ставка_дек'] = 1\n",
    "    #Замещенная ставка\n",
    "    df_t.loc[df_t['Признак_ШЕ'].str.contains('ЗАМ', na = False),'Ставка_зам'] = 1\n",
    "    #Техническая вакансия\n",
    "    df_t.loc[df_t.query('tech_date_st <= Дата_отчета <= tech_date_end').index, 'Ставка_тех'] = 1\n",
    "    #--удаляем вспомогательные столбцы с датами начала действия и окончания технической вакансии, которая была подтянута из справочника\n",
    "    df_t = df_t.drop(columns=['tech_date_st','tech_date_end'])\n",
    "    #статус по завершению обработки блока/функции\n",
    "    if_success(unit)\n",
    "except Exception as e:\n",
    "    err_descr (unit, e)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "719e3e79",
   "metadata": {},
   "source": [
    "#### Изменение типов данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "37e5449a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Выполнено: блок/функция 'Дополнительные столбцы по статичному меппингу'\n"
     ]
    }
   ],
   "source": [
    "#наименование функции или блока для отработки ошибок\n",
    "unit = 'Дополнительные столбцы по статичному меппингу'\n",
    "try:\n",
    "    #изменение текущих столбцов с float to int\n",
    "    #--столбцы к конвертации\n",
    "    flt_int_cols = ['id','ТН','Ставка_вак','Ставка_дек','Ставка_зам','Ставка_тех']\n",
    "    #--конвертация\n",
    "    df_t[flt_int_cols] = df_t[flt_int_cols].fillna(0).astype('int')\n",
    "    #статус по завершению обработки блока/функции\n",
    "    if_success(unit)\n",
    "except Exception as e:\n",
    "    err_descr (unit, e)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac28f913",
   "metadata": {},
   "source": [
    "#### Дополнительные столбцы по виртуальным меппингам\n",
    "Применяем меппинги, которые были созданы во время обработки выгрузки"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8855eaa2",
   "metadata": {},
   "source": [
    "* Увольняющиеся сотрудники по дате увольнения"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2aab4b9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Выполнено: блок/функция 'Увольняющиеся сотрудники по дате увольнения'\n"
     ]
    }
   ],
   "source": [
    "#наименование функции или блока для отработки ошибок\n",
    "unit = 'Увольняющиеся сотрудники по дате увольнения'\n",
    "try:\n",
    "    #формируем отдельную таблицу по увольняемым сотрудникам, у которых проставлены даты увольнения\n",
    "    df_fired = df_t.groupby(['id','Дата_увольнения']).agg(Количество = ('id','count')).iloc[:,:-1].reset_index()\n",
    "    #прибавляем 1 день к дате увольнения т.к. если стоит последний день, то сотрудник ещё числится в штате \n",
    "    df_fired.loc[:,'Дата_увольнения'] += pd.DateOffset(days=1)\n",
    "    #добавляем признак уволенного сотрудника\n",
    "    df_t = df_t.merge(df_fired,\n",
    "               left_on = [df_t.id, df_t.Дата_отчета.dt.year, df_t.Дата_отчета.dt.month], \n",
    "               right_on = [df_fired.id, df_fired.Дата_увольнения.dt.year, df_fired.Дата_увольнения.dt.month], \n",
    "               how = \"left\", suffixes = ['','_факт']).iloc[:,3:].drop(columns = ['id_факт'])\n",
    "    #очистка переменной временной таблицы\n",
    "    df_fired = None\n",
    "    #статус по завершению обработки блока/функции\n",
    "    if_success(unit)\n",
    "except Exception as e:\n",
    "    err_descr (unit, e)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b299c8b",
   "metadata": {},
   "source": [
    "* Длительность поиска сотрудника на вакансию"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1650cf6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Выполнено: блок/функция 'Длительность поиска сотрудника на вакансию'\n"
     ]
    }
   ],
   "source": [
    "#наименование функции или блока для отработки ошибок\n",
    "unit = 'Длительность поиска сотрудника на вакансию'\n",
    "try:\n",
    "    #создаем справочник, в котором будут только штатные единицы с вакансиями\n",
    "    df_vac = df_t[df_t['Ставка_вак'] == 1].groupby(['id','Дата_отчета']).agg(Количество = ('id','count')).reset_index()\n",
    "    #--создаем столбец отклонения последовательности, в котором сравниваются даты в рамках одной группы \"id\" по последовательности дат, если месяц за месяцем, то расчитывается количество дней\n",
    "    df_vac.loc[:,'Отклонение_последовательности'] = df_vac.groupby('id')[['id','Дата_отчета']].diff(1)['Дата_отчета']\n",
    "    #--по отклонениям свыше 31 дня ставим NaN т.к. мы ищем только отклонение Month-to-Month\n",
    "    df_vac.loc[df_vac['Отклонение_последовательности'] > pd.Timedelta('31 days'),'Отклонение_последовательности'] = None\n",
    "    #--ставим дату как в источнике, если отклонение пустое, это означает, что это стартовая дата т.к. перед ней нет сравнительных дат\n",
    "    df_vac.loc[df_vac['Отклонение_последовательности'].isnull(),'Дата_начала_последовательности'] = df_vac['Дата_отчета']\n",
    "    #--меняем формат данных id на int, для того чтобы в функции merge_asof корректно определялся параметр by\n",
    "    df_vac['id'] = df_vac['id'].astype('int')\n",
    "    #итоговая таблица с меппингом\n",
    "    #--создаем столбец, от которого будем рассчитывать протяженность последовательного наличия вакантной ставки с помощью merge_asof, суть в том, что к ID из левой таблицы будут браться даты ближайшие от правой таблицы и мы поймем, сколько ставка у нас находится в поиске\n",
    "    df_vac = pd.merge_asof(df_vac.sort_values(by=['Дата_отчета','id']),\n",
    "                           df_vac[['id','Дата_начала_последовательности']].query(\"Дата_начала_последовательности.notnull()\").sort_values(by=['Дата_начала_последовательности','id']), \n",
    "                           left_on='Дата_отчета', \n",
    "                           right_on = 'Дата_начала_последовательности', \n",
    "                           by = 'id',\n",
    "                           suffixes=('','_расчет'),\n",
    "                           direction='backward')\n",
    "    #рассчитываем длительность поиска по вакансии и прибавляем 1 день т.к. отклонение месяц в месяц будет нулем\n",
    "    df_vac['Вакансия_длительность_поиска'] = (df_vac['Дата_отчета'].dt.to_period('M').astype('int64') - df_vac['Дата_начала_последовательности_расчет'].dt.to_period('M').astype('int64')) + 1\n",
    "    #убираем лишние столбцы\n",
    "    df_vac = df_vac.iloc[:,[0,1,-1]]\n",
    "    #применяем соединиение с основной таблицей\n",
    "    df_t = df_t.merge(df_vac,\n",
    "               on = ['id', 'Дата_отчета'], \n",
    "               how = \"left\")\n",
    "    #очистка переменной временной таблицы\n",
    "    df_vac = None\n",
    "    #статус по завершению обработки блока/функции\n",
    "    if_success(unit)\n",
    "except Exception as e:\n",
    "    err_descr (unit, e)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d617539a",
   "metadata": {},
   "source": [
    "* Перемещения внутри ID<br>\n",
    " *В данной проверке мы проверяем помесячно по каждой ID, были ли какие-либо действия внутри ID в части табельного номера, если да, будет проставлен признак `1`*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4d327196",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Выполнено: блок/функция 'Перемещения внутри ID'\n"
     ]
    }
   ],
   "source": [
    "#наименование функции или блока для отработки ошибок\n",
    "unit = 'Перемещения внутри ID'\n",
    "try:\n",
    "    #СОЗДАНИЕ МЕППИНГА ID - Дата отчета - ТН\n",
    "    #--создаем таблицу с ID, датами отчетов и объединенными ТН, в случае если на ID несколько ТН\n",
    "    df_movement = df_t.groupby(['id','Дата_отчета'])['ТН'].apply(list).reset_index()\n",
    "    #--создаем столбец со сдвигом в +1 месяц, чтобы сравнить текущие данные с предыдущим месяцем т.е. в сдвинутой дате не будет предыдущего месяца\n",
    "    df_movement['Дата_отчета_сдвиг'] = df_movement['Дата_отчета'] + pd.DateOffset(months=1)\n",
    "    #--путем соединения текущей и сдвинутой даты, показываем, какой ТН был в прошлом месяце\n",
    "    df_movement = df_movement.merge(df_movement, \n",
    "                                      left_on = ['id','Дата_отчета'], \n",
    "                                      right_on = ['id','Дата_отчета_сдвиг'], \n",
    "                                      how = 'left', \n",
    "                                      suffixes = ['','_пред']).drop(columns=['Дата_отчета_пред','Дата_отчета_сдвиг_пред'])\n",
    "    #--добавляем столбец минимальной даты по id, чтобы исключить ненайденные значения т.к. проверять менее минимальной невозможно\n",
    "    df_movement = df_movement.merge(df_t.groupby(['id']).agg(Дата_мин=('Дата_отчета',np.min)).reset_index(),\n",
    "                                      left_on = ['id','Дата_отчета'], \n",
    "                                      right_on = ['id','Дата_мин'], \n",
    "                                      how = 'left')\n",
    "    #--если дата отчета совпадает с минимальной датой, то ставим ТН_пред равный ТН т.к. предыдущих данных нет для сравнения\n",
    "    df_movement.loc[df_movement['Дата_отчета'] == df_movement['Дата_мин'], 'ТН_пред'] = df_movement['ТН']\n",
    "    #--осуществляем проверку, если ТН и ТН_пред совпадает, значит по ID штатной единицы изменений не было, если нет, то значит произошло изменение\n",
    "    df_movement.loc[df_movement['ТН'] != df_movement['ТН_пред'], 'ID_изменение'] = 1\n",
    "    #--оставляем только те ID, по которым происходили изменения\n",
    "    df_movement = df_movement.query(\"ID_изменение > 0\")\n",
    "    #ОБЪЕДИНЕНИЕ С ИТОГОВОЙ ТАБЛИЦЕЙ\n",
    "    #применяем соединиение с основной таблицей\n",
    "    df_t = df_t.merge(df_movement[['id','Дата_отчета','ID_изменение']],\n",
    "                      on = ['id', 'Дата_отчета'], \n",
    "                      how = \"left\", \n",
    "                      suffixes = ['','_пред'])\n",
    "    #очистка переменной временной таблицы\n",
    "    df_movement = None\n",
    "    #статус по завершению обработки блока/функции\n",
    "    if_success(unit)\n",
    "except Exception as e:\n",
    "    err_descr (unit, e)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f7e6ed5",
   "metadata": {},
   "source": [
    "* Новые и ушедшие ТН<br>\n",
    " *В данной проверке мы проводим сверку по всем табельным номерам: 1) если в предыдущем месяце нет, значит ТН новый 2) если из прошлого месяца сотрудника нет, значит такого ТН больше нет*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "dd6fabb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Выполнено: блок/функция 'Новые и ушедшие ТН'\n"
     ]
    }
   ],
   "source": [
    "#наименование функции или блока для отработки ошибок\n",
    "unit = 'Новые и ушедшие ТН'\n",
    "try:\n",
    "    #СОЗДАНИЕ МЕППИНГА Дата отчета - ТН\n",
    "    #--создаем таблицу с датами отчетов и ТН\n",
    "    df_retired_new = df_t.query('ТН != 0').groupby(['ТН','Дата_отчета']).agg(Количество=('ТН','count')).reset_index()\n",
    "    #--создаем столбец со сдвигом даты отчета в +1 месяц, чтобы сравнить текущие данные с предыдущим месяцем и наоборот т.е. в сдвинутой дате не будет предыдущего месяца\n",
    "    df_retired_new['Дата_отчета_сдвиг'] = df_retired_new['Дата_отчета'] + pd.DateOffset(months=1)\n",
    "    #--путем соединения текущей и сдвинутой даты, показываем, какой ТН был в прошлом месяце\n",
    "    df_retired_new = df_retired_new.merge(df_retired_new, \n",
    "                                      left_on = ['ТН','Дата_отчета'], \n",
    "                                      right_on = ['ТН','Дата_отчета_сдвиг'], \n",
    "                                      how = 'left', \n",
    "                                      suffixes = ['','_пред']).drop(columns=['Дата_отчета_пред','Дата_отчета_сдвиг_пред'])\n",
    "    #--путем соединения текущей и сдвинутой даты, показываем, какой ТН присутствует в следующем месяце\n",
    "    df_retired_new = df_retired_new.merge(df_retired_new, \n",
    "                                      left_on = ['ТН','Дата_отчета_сдвиг'], \n",
    "                                      right_on = ['ТН','Дата_отчета'], \n",
    "                                      how = 'left', \n",
    "                                      suffixes = ['','_след']).drop(columns=['Количество_пред_след','Дата_отчета_след','Дата_отчета_сдвиг_след'])\n",
    "    #--если дата отчета совпадает с минимальной/максимальной датой, то ставим Количество_пред/Количество_след соответственно равный столбцу Количество т.к. предыдущих/будущих данных нет для сравнения\n",
    "    df_retired_new.loc[df_retired_new['Дата_отчета'] == df_retired_new['Дата_отчета'].min(), 'Количество_пред'] = 1\n",
    "    df_retired_new.loc[df_retired_new['Дата_отчета'] == df_retired_new['Дата_отчета'].max(), 'Количество_след'] = 1\n",
    "    #--меняем признаки, 1 в 0, NaN в 1 т.к. именно NaN показывал, что значение не было найдено\n",
    "    df_retired_new.iloc[:,4:] = (df_retired_new.iloc[:,4:] - 1).fillna(1)\n",
    "    #--переименуем последние столбцы\n",
    "    df_retired_new.rename({'Количество_пред': 'ТН_новый', 'Количество_след': 'ТН_ушедший'}, axis=1, inplace=True)\n",
    "    #ОБЪЕДИНЕНИЕ С ИТОГОВОЙ ТАБЛИЦЕЙ\n",
    "    #--применяем соединиение с основной таблицей\n",
    "    df_t = df_t.merge(df_retired_new[['ТН','Дата_отчета','ТН_новый','ТН_ушедший']],\n",
    "                      on = ['ТН', 'Дата_отчета'], \n",
    "                      how = \"left\", \n",
    "                      suffixes = ['','_пред'])\n",
    "    #--добавляем новый столбец с датой отчета со сдвигом на 1 месяц вперед, чтобы в отчетности видеть к какому месяцу относится увольнения т.к. мы сверяли предыдущий с текущим и проставляли признак уволенного в предыдущем, но по факту сотрудник ещё был в этом месяце\n",
    "    df_t['Дата_отчета_сдвиг'] = df_t['Дата_отчета'] + pd.DateOffset(months=1)\n",
    "    #очистка переменной таблицы меппинга\n",
    "    df_retired_new = None\n",
    "    #статус по завершению обработки блока/функции\n",
    "    if_success(unit)\n",
    "except Exception as e:\n",
    "    err_descr (unit, e)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53b6c419",
   "metadata": {},
   "source": [
    "### Сохранение результата"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3aee335",
   "metadata": {},
   "source": [
    "Определяем последнюю дату по загруженным данным и вставим её в название файла"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7e19dac5",
   "metadata": {},
   "outputs": [],
   "source": [
    "report_date = str(df_t['Дата_отчета'].max().date())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41325504",
   "metadata": {},
   "source": [
    "Сохраняем таблицу в файл Excel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "fee42458",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Выполнено: блок/функция 'Сохранение данных'\n"
     ]
    }
   ],
   "source": [
    "unit = 'Сохранение данных'\n",
    "try:\n",
    "    df_t.to_excel(file_strg + \"\\\\reports\\staff_regions_report_\" + report_date + \".xlsx\", sheet_name = 'Данные', index = False)\n",
    "    #статус по завершению обработки блока/функции\n",
    "    if_success(unit)\n",
    "except Exception as e:\n",
    "    err_descr (unit, e)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dde366e4",
   "metadata": {},
   "source": [
    "Очистка переменных с основными таблицами"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0204c9dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#таблица исходная при загрузке\n",
    "#df_staff = None\n",
    "#копия таблицы для обработки\n",
    "#df_t = None"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
