{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "85979570",
   "metadata": {},
   "source": [
    "*Это рабочий код, представленный для ознакомления.*\n",
    "\n",
    "*Адреса файловых ресурсов скрыты,также не указаны настоящие наименование компаний-поставщиков данных.*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "895caa51",
   "metadata": {},
   "source": [
    "### Импортируем библиотеки"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2f2b88c",
   "metadata": {},
   "source": [
    "Увеличиваем ширину рабочей области на максимум"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "75590bf8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:90% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:90% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "220ca0a6",
   "metadata": {},
   "source": [
    "Загружаем основные библиотеки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3dfc87b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#открываем необходимые библиотеки\n",
    "import sys\n",
    "import sqlite3 as sql3\n",
    "import pandas as pd\n",
    "import openpyxl\n",
    "import os\n",
    "import datetime\n",
    "import numpy as np\n",
    "from sklearn.neighbors import BallTree\n",
    "#адрес БД SQLite\n",
    "lct_cn = r'\\\\*Development\\Apps\\Py_projects\\04_real_estate\\datasets\\sqlite_db\\db_04_real_estate.db'\n",
    "#Отключение предупреждения Pandas \"SettingWithCopyWarning:A value is trying to be set on a copy of a slice from a DataFrame\"\n",
    "pd.options.mode.chained_assignment = None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1c4d6a9",
   "metadata": {},
   "source": [
    "### Проверяем справочник `geo` на наличие всех городов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bc80fdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def unknown_cities_in_the_dictionary(geodic_q, geodic_y, sapdic_q, sapdic_y):\n",
    "    #Открываем файлы\n",
    "    try:\n",
    "        #читаем файл словаря АД > извлекаем только 2 столбца > Удаляем дубликаты\n",
    "        f1 = pd.read_csv(open(r'\\\\*\\Apps\\Py_projects\\04_real_estate\\datasets\\dictionaries' + '\\\\' + str(geodic_y) + '\\\\04_datasets_dict_geo_0' + str(geodic_q) + '-' + str(geodic_y) + '.csv','r'), sep=';', decimal='.', usecols= ['city_sap','region_sap']).drop_duplicates().reset_index(drop=True)\n",
    "        #читаем файл SAP > извлекаем только 3 столбца > делаем запрос Тип АО == \"Зданию и Сооружению\" и непрофиль == Нет > Выбираем 2 столбца > Удаляем дубликаты\n",
    "        f2 = pd.read_excel(open(r'\\\\*\\Real Estate\\\\' + str(sapdic_y) + '\\SAPRE_0' + str(sapdic_q) + '-' + str(sapdic_y) + '.xlsx','rb'), sheet_name=\"Sheet1\", usecols = ['Город','Регион','Тип АО','Непрофильный актив']).query('`Тип АО` in (\"Здание\") & `Непрофильный актив` == \"Нет\"').groupby(['Город','Регион']).agg(Count_obj=('Город','count')).reset_index()\n",
    "        #Проводим сравнение\n",
    "        return f1.merge(f2, left_on = ['city_sap','region_sap'], right_on = ['Город','Регион'], how = 'right').query('city_sap.isna()', engine=\"python\")\n",
    "    except OSError as e:\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9146bb0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "unknown_cities_in_the_dictionary (geodic_q = 2, geodic_y = 2022, sapdic_q = 2, sapdic_y = 2022)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bd317b6",
   "metadata": {},
   "source": [
    "### Загрузка файла АД ПРЕДПРИЯТИЕ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27f49964",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_ad_data(q,y):\n",
    "    # Подключаемся к БД\n",
    "    ConnectSQLite(lct_cn)\n",
    "    #перед этим удаляем старые данные\n",
    "    #!!! ПРОВЕРЯЙ ЧТО УДАЛЯЕШЬ, ЕСЛИ МЕНЯЕШЬ ВСЕ ДАННЫЕ, ТО НАДО УБРАТЬ УСЛОВИЕ WHERE\n",
    "    ExecQuerySQLite ('DELETE FROM [ad_rent] WHERE year = ' + str(y))\n",
    "    #загружаем в SQLite\n",
    "    SendDataToSQLite(pd.read_csv(open(r'\\\\*\\Apps\\Py_projects\\04_real_estate\\datasets\\main\\ad' + '\\\\' + str(y) + '\\\\04_datasets_main_ad_0' + str(q) + '-' + str(y) + '.csv', 'r'), delimiter = ';'), 'ad_rent', 'append')\n",
    "    # Закрытие соединения\n",
    "    DisconnectSQLite()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b714f2a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "load_ad_data (2,2022)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76c6fb6c",
   "metadata": {},
   "source": [
    "### Расчет минимальных и максимальных сумм в разрезе городов/регионов по АД"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e915336",
   "metadata": {},
   "outputs": [],
   "source": [
    "#открываем таблицу и создаем датасет ad_data_mm (min_max)\n",
    "ad_data_mm = pd.read_csv(open(r'\\\\*\\Apps\\Py_projects\\04_real_estate\\datasets\\main\\ad\\2022\\04_datasets_main_ad_02-2022.csv', 'r'), delimiter = ';')\n",
    "#создаем доп столбцы\n",
    "ad_data_mm['cost_sum'] = ad_data_mm[['cost_1q','cost_2q','cost_3q','cost_4q']].sum(axis=1, min_count=1)\n",
    "ad_data_mm['area_sum'] = ad_data_mm[['area_1q','area_2q','area_3q','area_4q']].sum(axis=1, min_count=1)\n",
    "ad_data_mm['cost_per_1qm'] = ad_data_mm['cost_sum'] / ad_data_mm['area_sum']\n",
    "#добавляем таблицу с гео-мэпингом\n",
    "geo_dict = pd.read_csv(open(r'\\\\*\\Apps\\Py_projects\\04_real_estate\\datasets\\dictionaries\\2022\\04_datasets_dict_geo_02-2022.csv','r'), delimiter = ';')\n",
    "#добавляем признак расширенного филиала\n",
    "ad_data_mm = ad_data_mm.merge(geo_dict[['city_sap','region_sap','branch_add']], left_on = ['city_sap','region_sap'], right_on = ['city_sap','region_sap'], how = 'left' )\n",
    "#получаем таблицу со средними значениями до города, в т.ч. минимумы и максимумы\n",
    "ad_data_mm = ad_data_mm.groupby(['year','branch_add','region_sap','city_sap','address']).agg(\n",
    "    mean_cost = ('cost_per_1qm','mean')\n",
    "    ).reset_index().groupby(['year','branch_add','region_sap','city_sap']).agg(\n",
    "    mean_cost = ('mean_cost','mean'), min_cost = ('mean_cost','min'), max_cost = ('mean_cost','max')).reset_index()\n",
    "#используем коеффициент 0.25 для уменьшения минимальной средней и максимальной средний т.е создаем коридор цен на квадратный метр\n",
    "ad_data_mm[['min_cost','max_cost']]*= np.array([0.75, 1.25])\n",
    "\n",
    "ad_data_mm.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da0a5c12",
   "metadata": {},
   "source": [
    "### Предобработка файла НЕДВИЖИМОСТИ\n",
    "На данном этапе выполняем следующее:\n",
    "* фильтруем исходный файл НЕДВИЖИМОСТИ по признакам (статус, категория, тип зданя и т.д)\n",
    "* заменяем районы, по Москве это Зеленоград и Троицк, а по СПБ это Сестрорецк, Петергоф и прочие\n",
    "* отсеиваем данные НЕДВИЖИМОСТЬ которые не проходят по диапазонам цен за квадратный метр, а также городам присутствия"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "653fd2c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ProcessrealestateSourceFile (realestate_q, realestate_y, geodic_q, geodic_y):\n",
    "    #данная функция должна использоваться с подключением к БД SQL\n",
    "    #добавить район для Москва (acv_geo_dis_raion) и \n",
    "    #справочник для загрузки файла\n",
    "    realestate_dict = {'realestate_id':'int64',\n",
    "                     'url':'object',\n",
    "                     'status_id':'int64',\n",
    "                     'creationdate':'object',\n",
    "                     'category_id':'int64',\n",
    "                     'inputtype_id':'int64',\n",
    "                     'floornumber':'int64',\n",
    "                     'buildingtype_id':'int64',\n",
    "                     'placementtype_id':'int64',\n",
    "                     'conditiontype_id':'int64',\n",
    "                     'acv_geo_region':'object',\n",
    "                     'acv_geo_dis_okrug':'object',\n",
    "                     'acv_geo_dis_raion':'object',\n",
    "                     'acv_geo_dis_mikroraion':'object',\n",
    "                     'acv_geo_gorod':'object',\n",
    "                     'acv_geo_street':'object',\n",
    "                     'acv_geo_house':'object',\n",
    "                     'lat':'int64',\n",
    "                     'lng':'int64',\n",
    "                     'totalarea':'int64',\n",
    "                     'bargainterms_currency':'object',\n",
    "                     'bargainterms_price':'int64'}\n",
    "    #справочник по геоданным\n",
    "    geo_dict = pd.read_csv(open(r'\\\\*\\Apps\\Py_projects\\04_real_estate\\datasets\\dictionaries' + '\\\\' + str(geodic_y) + '\\\\04_datasets_dict_geo_0' + str(geodic_q) + '-' + str(geodic_y) + '.csv','r'), delimiter = ';')\n",
    "    #фильтры\n",
    "    st_id = 1 #активные\n",
    "    cat_id = 5 #аренда\n",
    "    build_id = [1,2,3,4,13,17,18,19,22,28,30,31,33,34,38,42,43,44,45,46,49] #типы зданий, см.меппинг\n",
    "    floor_n = 1 #этаж\n",
    "    area = 40 #площадь >=\n",
    "    city = list(geo_dict['city_realestate'].unique())\n",
    "    region = list(geo_dict['region_realestate'].unique())\n",
    "    #\n",
    "    #чтение файла\n",
    "    with open(r'\\\\*\\Data\\realestate\\realestate_src_0' + str(realestate_q) + '-' + str(realestate_y) + '.csv','r',encoding=\"utf8\") as t:\n",
    "        t = pd.read_csv(t, usecols = list(realestate_dict.keys()))\n",
    "        #изменение формата столбца для даты\n",
    "        t['creationdate'] = t['creationdate'].astype('datetime64[ns]')\n",
    "        #сохраняем в переменную отфильтрованные по основным фильтрам данные\n",
    "        t_temp = t.query(\n",
    "            '''\n",
    "                ((status_id != @st_id & creationdate.dt.year==@realestate_y & creationdate.dt.quarter==@realestate_q) | (status_id == @st_id)) & \\\n",
    "                category_id == @cat_id & \\\n",
    "                ((buildingtype_id in @build_id) | (placementtype_id.notnull() & buildingtype_id.isnull())) & \\\n",
    "                floornumber == @floor_n & \\\n",
    "                totalarea >= @area & \\\n",
    "                acv_geo_gorod in @city & \\\n",
    "                bargainterms_currency == \"rur\"\n",
    "            '''\n",
    "            , engine = 'python'\n",
    "            )\n",
    "    #\n",
    "    #делаем замену по районам, по Москве это Зеленоград и Троицк, а по СПБ это Сестрорецк, Петергоф и прочие\n",
    "    #переменные по округам\n",
    "    city_region = geo_dict[['city_realestate','region_realestate']].agg(''.join, axis = 1) #используется в дальнейшем как ключ\n",
    "    moscow_add_okrug = ['тао (троицкий)','зелао'] #округа по полю 'acv_geo_dis_okrug', к замене\n",
    "    spb_add_okrug = ['колпино','кронштадт','петергоф','пушкин','сестрорецк'] #округа по полю 'acv_geo_dis_okrug', к замене\n",
    "    #переменные с условиями и результатам к условиям\n",
    "    conditions = [t_temp['acv_geo_dis_okrug'].isin(moscow_add_okrug), t_temp['acv_geo_dis_mikroraion'].isin(spb_add_okrug)] #условия поиска, указываем сразу 2\n",
    "    choices = [t_temp['acv_geo_dis_okrug'],t_temp['acv_geo_dis_mikroraion']] #возвращаемый результат из условий\n",
    "    t_temp['acv_geo_region'] = np.select(conditions, choices, default = t_temp['acv_geo_region']) #результат с заменой\n",
    "    #убираем регионы, которые не включены в справочник tGeo\n",
    "    t_temp = t_temp.query('acv_geo_gorod + acv_geo_region in @city_region', engine = 'python').reset_index(drop=True)\n",
    "    #добавляем города из мэпинга SAP\n",
    "    t_temp[['acv_geo_gorod_map','acv_geo_region_map']] = pd.merge(\n",
    "        t_temp,\n",
    "        geo_dict[['city_realestate','region_realestate','city_sap','region_sap']], \n",
    "        left_on = ['acv_geo_gorod','acv_geo_region'], \n",
    "        right_on = ['city_realestate','region_realestate'],\n",
    "        how = 'left'\n",
    "        )[['city_sap','region_sap']]\n",
    "    #отправляем в SQLite отфильтрованные данные НЕДВИЖИМОСТЬ без учета диапазона цен\n",
    "    SendDataToSQLite(t_temp, 'realestate_src_0' + str(realestate_q) + '-' + str(realestate_y), 'replace')\n",
    "    #отделяем диапазон между минимумом и максимумом\n",
    "    t_temp = t_temp.merge( #добавляем столбцы, для определения вхождения данных НЕДВИЖИМОСТЬ в диапазон затрат на квадратный метр (на основе данных АД), стыкуемся по столбцам \"_map\" т.к. там учтены областные городы, типа Троицка, Зелика и прочее\n",
    "        ad_data_mm[ad_data_mm['year'] == realestate_y][['city_sap','region_sap','min_cost','max_cost']], \n",
    "        left_on = ['acv_geo_gorod_map','acv_geo_region_map'], \n",
    "        right_on = ['city_sap','region_sap'], \n",
    "        how = 'inner'\n",
    "    ).query( #теперь отделяем затраты и оставляем только в пределах диапазона\n",
    "    'min_cost <= (bargainterms_price / totalarea) <= max_cost'\n",
    "    ).drop(columns=['min_cost','max_cost','city_sap','region_sap']) #удаляем лишние столбцы\n",
    "    #добавляем столбцы с годом и кварталом\n",
    "    t_temp['year'] = realestate_y\n",
    "    t_temp['quarter'] = realestate_q\n",
    "    #отправляем данные в SQLite с учетом диапазона цен\n",
    "    #..перед этим удаляем старые данные\n",
    "    ExecQuerySQLite ('DELETE FROM [realestate_ads] WHERE year = ' + str(realestate_y) + ' and quarter = ' + str(realestate_q))\n",
    "    #..загружаем новые\n",
    "    SendDataToSQLite(t_temp, 'realestate_ads', 'append')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8500aa33",
   "metadata": {},
   "source": [
    "#### Применение функции"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29cbe5c5",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#ограничение выгрузки\n",
    "restr = [1,2022]\n",
    "# Подключаемся к БД\n",
    "ConnectSQLite(lct_cn)\n",
    "#перебираем все года и кварталы\n",
    "for y in range(2020, 2023):\n",
    "    for q in range(1, 5):\n",
    "        if restr[1] == y and restr[0]+1 == q: break\n",
    "        print('Обработка таблицы: год - {}, квартал - {}'.format(y,q))\n",
    "        ProcessrealestateSourceFile (realestate_q = q, realestate_y = y, geodic_q = 2, geodic_y = 2022)\n",
    "# Закрытие соединения\n",
    "DisconnectSQLite()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "314f5845",
   "metadata": {},
   "source": [
    "### Поиск альтернатив"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "168b07e0",
   "metadata": {},
   "source": [
    "#### Загружаем данные АД и НЕДВИЖИМОСТЬ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "247dac71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Подключаемся к БД\n",
    "ConnectSQLite(lct_cn)\n",
    "#данные НЕДВИЖИМОСТЬ\n",
    "df = GetDataFromSQLite ('SELECT * FROM realestate_ads')\n",
    "#данные АД ПРЕДПРИЯТИЕ\n",
    "df_ad =  GetDataFromSQLite ('SELECT * FROM ad_rent')\n",
    "# Закрытие соединения\n",
    "DisconnectSQLite()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "631fc893",
   "metadata": {},
   "source": [
    "#### Ищем альтернативы"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b470e33f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#функция поиск альтернативных объектов в определенном радиусе\n",
    "def get_alternatives_from_realestate(y, q):\n",
    "    radius = 6371000 #радиус Земли\n",
    "    max_distance = 1500 / radius #ограничение в поиске в метрах\n",
    "    coord_1 = np.radians(df.query('year==@y & quarter == @q')[['lat','lng']].values) #коордианаты альтернативы\n",
    "    coord_2 = np.radians(df_ad.query('year==@y')[['lat','lng']].values) #координаты объектов банка, к которым будем искать альтернативы\n",
    "    tree = BallTree(coord_1, metric = 'haversine') #создаем дерево, по которому будем перебирать координаты\n",
    "    return tree.query_radius(coord_2, r=max_distance, return_distance  = True, sort_results = True) #ищем по каждому индексу (строке) ближайшие координаты в метрах"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fcac9c8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#создадим функцию, которая будет формировать таблицу из списков альтернатив\n",
    "def construct_data_from_list_alternative(y,q,i):\n",
    "    df_temp = pd.DataFrame(\n",
    "            [\n",
    "                [str(i)] * len(ind[i]),\n",
    "                list(ind[i]),\n",
    "                list(results[i]*radius),\n",
    "                [str(list(df_ad.query('year==@y').reset_index().iloc[[i]]['id_sap'].values)[0])] * len(ind[i])\n",
    "            ]\n",
    "                ).T.rename(columns={0:'ad_index_alt',1:'realestate_index_alt',2:'distance_alt',3:'id_sap_alt'})\n",
    "    return df.query('year==@y & quarter == @q').reset_index().iloc[ind[i]].merge(df_temp, left_index=True, right_on = 'realestate_index_alt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d2376e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ограничение выгрузки\n",
    "restr = [1,2022]\n",
    "#затираем итоговую таблицу перед обработкой\n",
    "data_alt = pd.DataFrame()\n",
    "#перебираем все года и кварталы\n",
    "for y in range(2020, 2023):\n",
    "    for q in range(1, 5):\n",
    "        #уведомление\n",
    "        print('Обработка таблицы: год - {}, квартал - {}'.format(y, q))\n",
    "        #если доходим до ограничения, выходим\n",
    "        if restr[1] == y and restr[0]+1 == q: break\n",
    "        #индексы строк НЕДВИЖИМОСТЬ и результат в расстоянии\n",
    "        ind, results = get_alternatives_from_realestate (y, q)\n",
    "        #перебираем все строки таблицы АД и ищем им альтернативы\n",
    "        for i in range(len(df_ad.query('year == @y'))):\n",
    "            if list(ind[i]):\n",
    "                #формируем временную таблицу с данными НЕДВИЖИМОСТЬ соседями\n",
    "                df_temp = construct_data_from_list_alternative (y, q, i)\n",
    "                #оставляем только те объявления, при которых координаты и площадь одинаковые, но создан последним (неочевидные дубликаты)\n",
    "                df_temp = df_temp[df_temp['creationdate'].groupby(df_temp[['lat','lng','totalarea']].astype(str).apply('_'.join, 1)).apply(lambda x: x == x.max())]\n",
    "                #оставляем только те объявления, при которых координаты и площадь одинаковые, при этом только наиболее дешевые будут\n",
    "                df_temp = df_temp[df_temp['bargainterms_price'].groupby(df_temp[['lat','lng','totalarea']].astype(str).apply('_'.join, 1)).apply(lambda x: x == x.min())]\n",
    "                #удаляем очевидные дубликаты, если имеются одинаковые цены\n",
    "                df_temp = df_temp.drop_duplicates(subset=['lat','lng','totalarea','bargainterms_price'])\n",
    "                #отсеиваем площади, смотрим какая площадь на объекте в АД и подбираем аналоги в пределах +/- 25%\n",
    "                ad_obj_area = list(df_ad.query('year==@y').reset_index().iloc[[i]]['area_' + str(q) + 'q'].values)[0]\n",
    "                df_temp = df_temp.query('(@ad_obj_area*0.75) <= totalarea <= (@ad_obj_area*1.25)')\n",
    "                #заполняем сводный файл\n",
    "                if data_alt.empty:\n",
    "                    data_alt = df_temp\n",
    "                else:\n",
    "                    data_alt = pd.concat([data_alt, df_temp])\n",
    "                #очищаем\n",
    "                df_temp = None\n",
    "#удалеяем столбцы с индексами, которые уже нам не нужны\n",
    "data_alt = data_alt.drop(columns=['ad_index_alt','realestate_index_alt','index']) #p.s столбец index необходимо удалить в самом начале методом drop = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74ba6320",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ОТПРАВКА В SQLITE\n",
    "# Подключаемся к БД\n",
    "ConnectSQLite(lct_cn)\n",
    "#перед этим удаляем старые данные\n",
    "#ExecQuerySQLite ('DELETE FROM [realestate_alt]')\n",
    "#загружаем в SQLite\n",
    "SendDataToSQLite(data_alt, 'realestate_alt', 'append')\n",
    "# Закрытие соединения\n",
    "DisconnectSQLite()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83174dbb",
   "metadata": {},
   "source": [
    "### Формирование итоговой таблицы\n",
    "Таблица realestate_total будет использоваться во всех расчетах, кроме поиска альтернатив"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c65acbe",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#СОЗДАЕМ ИТОГОВУЮ ТАБЛИЦУ ПО АД ПРЕДПРИЯТИЕ\n",
    "# Подключаемся к БД\n",
    "ConnectSQLite(lct_cn)\n",
    "# получаем данные\n",
    "df = GetDataFromSQLite('SELECT * FROM ad_rent')\n",
    "#отключаемся от базы\n",
    "DisconnectSQLite()\n",
    "#ПЕРЕВОРОТ СТОЛБЦОВ В СТРОКИ\n",
    "#--временная таблица\n",
    "df_temp = df[['year','id_sap','address','district','city_sap','region_sap','cost_1q', 'cost_2q','cost_3q','cost_4q','area_1q', 'area_2q','area_3q','area_4q']]\n",
    "#--переворот столбцов в строки по суммам\n",
    "df_temp_1 = df_temp.melt(id_vars=['year','id_sap','address','district','city_sap','region_sap'], value_vars=['cost_1q', 'cost_2q','cost_3q','cost_4q'], var_name = 'quarter', value_name='price')\n",
    "df_temp_1['quarter']=df_temp_1['quarter'].str.extract('(\\d+)')\n",
    "#--переворот столбцов в строки по площадям\n",
    "df_temp_2 = df_temp.melt(id_vars=['year','id_sap','address','district','city_sap','region_sap'], value_vars=['area_1q', 'area_2q','area_3q','area_4q'], var_name = 'quarter', value_name='area')\n",
    "df_temp_2['quarter']=df_temp_2['quarter'].str.extract('(\\d+)')\n",
    "#--соединение временных таблиц в одну\n",
    "df_temp_1 = df_temp_1.merge(df_temp_2[['year','id_sap','quarter','area']], how='outer',on=['year','id_sap','quarter'])\n",
    "#--удаляем строки, если `price` нулевой, это касается ПРЕДПРИЯТИЕ т.к. делаем разворот из столбцов в строки\n",
    "df_temp_1 = df_temp_1[~df_temp_1['price'].isnull()].reset_index(drop=True)\n",
    "#цепляем справочник tGeo\n",
    "df_temp_1 = df_temp_1.merge(geo_dict[['city_sap','region_sap','branch_add','oap']], left_on = ['city_sap','region_sap'], right_on = ['city_sap','region_sap'], how = 'left' )\n",
    "#меняем названия столбцов\n",
    "df_temp_1.rename(columns={'city_sap':'city','region_sap':'region','id_sap_alt':'id_sap','oap':'pap','branch_add':'branch'}, inplace = True)\n",
    "#добавляем дополнительный столбец с признаком \"ГО/Регион\"\n",
    "df_temp_1['branch_group'] = ''\n",
    "df_temp_1.loc[df_temp_1['branch'].str.contains('ГО'),'branch_group'] = 'Москва и МО'\n",
    "df_temp_1.loc[~df_temp_1['branch'].str.contains('ГО'),'branch_group'] = 'Регионы'\n",
    "#добавляем расчетный столбец med_sqm\n",
    "df_temp_1['med_sqm'] = df_temp_1['price'] / df_temp_1['area']\n",
    "#!!! ТУТ МОЖНО ПЕРЕДАТЬ КУСОК В ФУНКЦИЮ, НЕ СДЕЛАЛ Т.К. ПО ВРЕМЕНИ НЕ УСПЕВАЛ\n",
    "#расчетные столбцы\n",
    "cols = ['district','city','pap','branch','branch_group','total'] #колонки, которые будем добавлять\n",
    "for c in cols:\n",
    "    #определяем столбцы для временной таблицы 1 и объединения 2\n",
    "    df_gr_cols_1 = ['year','quarter'] if c=='total' else ['year','quarter',c]\n",
    "    df_gr_cols_2 = ['year','quarter','med_'+c] if c=='total' else ['year','quarter',c,'med_'+c]\n",
    "    #формируем временную таблицу\n",
    "    df_temp = df_temp_1.groupby(df_gr_cols_1)['med_sqm'].median().reset_index()\n",
    "    df_temp.rename(columns={'med_sqm':'med_'+c}, inplace=True)\n",
    "    #добавляем в итоговую таблицу\n",
    "    df_temp_1 = df_temp_1.merge(df_temp[df_gr_cols_2], how='outer',on=df_gr_cols_1)\n",
    "    df_temp = None\n",
    "#--признак среза\n",
    "df_temp_1['source'] = 'company'\n",
    "#--пересортировка\n",
    "df_temp_1 = df_temp_1 [['source','year','quarter', 'id_sap', 'address', 'district', 'city', 'region','branch', 'pap', 'branch_group','price', 'area','med_sqm', 'med_district', 'med_city', 'med_pap', 'med_branch','med_branch_group', 'med_total']]\n",
    "#очищаем временную и начальную таблицу\n",
    "df_temp = None\n",
    "df_temp_2 = None\n",
    "df = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c0fe9ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "#СОЗДАЕМ ИТОГОВУЮ ТАБЛИЦУ ПО НЕДВИЖИМОСТЬ\n",
    "# Подключаемся к БД\n",
    "ConnectSQLite(lct_cn)\n",
    "# получаем данные\n",
    "df = GetDataFromSQLite('SELECT * FROM realestate_alt')\n",
    "df_ad = GetDataFromSQLite('SELECT year, id_sap, address, district FROM ad_rent')\n",
    "#отключаемся от базы\n",
    "DisconnectSQLite()\n",
    "#создаем столбец с расчетом затрат на квадратный метр\n",
    "df['sqm'] = df['bargainterms_price'] / df['totalarea']\n",
    "#формируем таблицу с подготовленными медианными значениями\n",
    "df_alt = df.groupby(['year','quarter','id_sap_alt','acv_geo_gorod_map','acv_geo_region_map']).agg(med_sqm=('sqm','median')).reset_index()\n",
    "#цепляем справочник tGeo\n",
    "df_alt = df_alt.merge(geo_dict[['city_sap','region_sap','branch_add','oap']], left_on = ['acv_geo_gorod_map','acv_geo_region_map'], right_on = ['city_sap','region_sap'], how = 'left' ).drop(columns=['city_sap','region_sap'])\n",
    "#добавим район из таблицы ad_rent\n",
    "df_alt = df_alt.merge(df_ad, left_on = ['year','id_sap_alt'], right_on = ['year','id_sap'], how = 'left' ).drop(columns=['id_sap'])\n",
    "#корректируем район, если это Москва или Питер, то оставляем, если нет, то пишем вместо пустоты или района Город !!! убрал т.к. формируется на этапе Excel в файле\n",
    "#df_alt.loc[~df_alt['acv_geo_gorod_map'].isin(['Москва г','Санкт-Петербург г']),'district'] = df_alt.loc[~df_alt['acv_geo_gorod_map'].isin(['Москва г','Санкт-Петербург г']),'acv_geo_gorod_map']\n",
    "\n",
    "#меняем названия столбцов\n",
    "df_alt.rename(columns={'acv_geo_gorod_map':'city','acv_geo_region_map':'region','id_sap_alt':'id_sap','oap':'pap','branch_add':'branch'}, inplace = True)\n",
    "\n",
    "#добавляем дополнительный столбец с признаком \"ГО/Регион\"\n",
    "df_alt['branch_group'] = ''\n",
    "df_alt.loc[df_alt['branch'].str.contains('ГО'),'branch_group'] = 'Москва и МО'\n",
    "df_alt.loc[~df_alt['branch'].str.contains('ГО'),'branch_group'] = 'Регионы'\n",
    "#расчетные столбцы\n",
    "cols = ['district','city','pap','branch','branch_group','total'] #колонки, которые будем добавлять\n",
    "for c in cols:\n",
    "    #определяем столбцы для временной таблицы 1 и объединения 2\n",
    "    df_gr_cols_1 = ['year','quarter'] if c=='total' else ['year','quarter',c]\n",
    "    df_gr_cols_2 = ['year','quarter','med_'+c] if c=='total' else ['year','quarter',c,'med_'+c]\n",
    "    #формируем временную таблицу\n",
    "    df_temp = df_alt.groupby(df_gr_cols_1)['med_sqm'].median().reset_index()\n",
    "    df_temp.rename(columns={'med_sqm':'med_'+c}, inplace=True)\n",
    "    #добавляем в итоговую таблицу\n",
    "    df_alt = df_alt.merge(df_temp[df_gr_cols_2], how='outer',on=df_gr_cols_1)\n",
    "    df_temp = None\n",
    "#--признак среза\n",
    "df_alt['source'] = 'realestate'\n",
    "#--пересортировка\n",
    "df_alt = df_alt[['source','year', 'quarter', 'id_sap', 'address','district', 'city', 'region', 'branch',  'pap',   'branch_group','med_sqm', 'med_district','med_city', 'med_pap', 'med_branch', 'med_branch_group','med_total']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbe7272d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#подключение к базе\n",
    "ConnectSQLite(lct_cn)\n",
    "#загрузка данных Предприятия\n",
    "ExecQuerySQLite('DELETE FROM realestate_total WHERE source=\"company\"')\n",
    "SendDataToSQLite(df_temp_1, 'realestate_total', 'append')\n",
    "#загрузка данных НЕДВИЖИМОСТЬ\n",
    "ExecQuerySQLite('DELETE FROM realestate_total WHERE source=\"realestate\"')\n",
    "SendDataToSQLite(df_alt, 'realestate_total', 'append')\n",
    "#создадим файл Excel для Access\n",
    "df_ttl = GetDataFromSQLite('SELECT * FROM realestate_total')\n",
    "df_ttl.to_excel(r'\\\\*\\Apps\\Py_projects\\04_real_estate\\datasets\\main\\ad\\2022_Q2_ttl.xlsx', sheet_name = f'realestate_total', encoding = 'windows-1251', index = False)                \n",
    "#отключаемся от БД\n",
    "DisconnectSQLite()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90a55880",
   "metadata": {},
   "source": [
    "### Дополнительные функции"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9805ce9f",
   "metadata": {},
   "source": [
    "Функция для расчета ближайший точек"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc7ab5a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def NearestPoints(q,y):\n",
    "    # Файлы загрузки и сохранения\n",
    "    # - DH_Rent_ForSQLite.csv (данные с адресами АД аренды + искуственно наложенный мэппинг по городам и координатам в аналогичном Excel файле)\n",
    "    # - realestate_Source (данные из SQLite, которые были обработаны и отфильтрованы согласно требованиям)\n",
    "    # - realestate_Uniq (сохраняемый файл, где отображены уникальные строки по ключевым столбцам 'lat'+'lng'+'totalarea'+'Converted_Price'\n",
    "    # Переменные\n",
    "    # - \"y\" - Фильтр дла данных DH_Rent_ForSQLite, файл ad_realestate_csv будет браться с уже определенным кварталом; также для указания года использованных данных (DH_Rent_ForSQLite и ad_realestate_csv) в конечном файле\n",
    "    # - \"q\" - для указания в конечном файле какой квартал использовался ad_realestate_csv\n",
    "    # Загружаем CSV\n",
    "    ad_csv = None\n",
    "    realestate_csv = None\n",
    "    ad_csv = pd.read_csv(open(r'\\\\*\\Apps\\Market Rental Rate Report\\csv\\DH_Rent_ForSQLite.csv','r'), sep = ';', decimal = '.') #!!! проверяй в координатах, чтобы не было точек т.к. будет восприниматься как текст\n",
    "    ad_csv = ad_csv.loc[ad_csv['Тип ОН']=='Точка продаж'].reset_index(drop=True)\n",
    "    ad_csv = ad_csv.loc[ad_csv['Год']==y].drop_duplicates(subset=['Адрес']).reset_index(drop=True)\n",
    "    # открываем realestate\n",
    "    realestate_csv = pd.read_csv (open(r'\\\\*\\Apps\\Market Rental Rate Report\\csv\\realestate_filtered\\realestate_fltrd_0' + str(q) + '-' + str(y) +'.csv','r'), sep=';', decimal = '.'\n",
    "        ,usecols = ['realestate_id','url','buildingtype_id','conditiontype_id','Филиал','ФилиалДоп','ПАП','acv_geo_region','acv_geo_gorod','street','lat','lng','totalarea','Converted_Price'])\n",
    "    #Оставляем в realestate_CSV только города, которые есть в ad_csv т.е. только в городах присутствия\n",
    "    arr_cities = ad_csv.drop_duplicates(subset=['Город'])['Город'].values\n",
    "    realestate_csv = realestate_csv.query('acv_geo_gorod in @arr_cities').reset_index(drop=True)\n",
    "    arr_cities = None\n",
    "    # Добавляем пользовательские столбцы\n",
    "    realestate_csv = realestate_csv.assign(**{'distance': 0, 'c_lat': 0, 'c_lng': 0, 'adr': 0, 'sort_id': 0, 'quarter': q, 'year': y})\n",
    "    #форматы столбцов\n",
    "    df_realestate_types = {'year':'int64', 'quarter':'int64','adr':'object', 'sort_id':'int64', 'c_lng':'float', 'c_lat':'float', 'distance':'float', 'realestate_id':'int64', 'url':'object','buildingtype_id':'object','conditiontype_id':'object', 'Филиал':'object', 'ФилиалДоп':'object', 'ПАП':'object', 'acv_geo_region':'object'\n",
    "        ,'acv_geo_gorod':'object','street':'object', 'lat':'float64', 'lng':'float64', 'totalarea':'float64', 'Converted_Price':'float64'}\n",
    "    # Меняем столбцы на числовой формат\n",
    "    realestate_csv.astype(df_realestate_types).dtypes\n",
    "    # Удаляем из таблицы строки, по которым Ключ: Широта+Долгота+Площадь больше минимальной строки с таким же ключом т.к. из дубликатов оставляем минимальный по сумме Converted_Price\n",
    "    realestate_csv = realestate_csv[realestate_csv['Converted_Price'].groupby(realestate_csv[['lat','lng','totalarea']].astype(str).apply('_'.join, 1)).apply(lambda x: x == x.min())]\n",
    "    # Удаляем дубликаты по тому же ключу т.к. если минимальные оставались одинаковые, то строки оставались без удаления\n",
    "    realestate_csv = realestate_csv.drop_duplicates(subset=['lat','lng','totalarea','Converted_Price'])\n",
    "    # - сохраняем в CSV и отправляем в SQLute\n",
    "    realestate_csv.to_csv(r'\\\\*\\Apps\\Market Rental Rate Report\\csv\\realestate_Uniq_0' + str(q) + '-' + str(y) +'.csv', sep=';', encoding='windows-1251', index = False)\n",
    "    UploadCSV2SQLite ('\\db_MRRP.db', 'DELETE FROM [realestate_ads] WHERE year = ' + str(y) + ' and quarter = ' + str(q),'\\realestate_Uniq_0' + str(q) + '-' + str(y) +'.csv','realestate_ads')\n",
    "    # Создаем подготовленный Dataframe для вывода результата\n",
    "    df_np = None\n",
    "    df_np = pd.DataFrame(columns=list(df_realestate_types.keys()))\n",
    "    # устанавливаем форматы столбцов\n",
    "    df_np.astype(df_realestate_types).dtypes\n",
    "    # Перебираем построчно данные АД и добавляем в таблицу итоговые данные\n",
    "    realestate_t = None\n",
    "    for r in ad_csv.itertuples():\n",
    "        # временная таблица\n",
    "        avg_sqr = ad_csv.iloc[r.Index, 9:13].mean()\n",
    "        realestate_t = realestate_csv.loc[(realestate_csv['acv_geo_gorod'] == ad_csv.iloc[r.Index,18]) & (realestate_csv['totalarea'] >= avg_sqr * 0.70) & (realestate_csv['totalarea'] <= avg_sqr * 1.3)]\n",
    "        # проверяем есть ли данные с таким городом в realestate_t, если нет, то идем дальше\n",
    "        if not realestate_t.empty:\n",
    "            # меняем в таблице realestate_CSV данные в столбцах сравниваемых координат, указываем координату от которой будем считать расстояние\n",
    "            realestate_t['year'] = int(y)\n",
    "            realestate_t['adr'] = ad_csv.iloc[r.Index,3]\n",
    "            realestate_t['c_lat'] = ad_csv.iloc[r.Index,21]\n",
    "            realestate_t['c_lng'] = ad_csv.iloc[r.Index,22]\n",
    "            # рассчитываем расстояние\n",
    "            realestate_t['distance'] = haversine(realestate_t.loc[0:,'c_lat'],realestate_t.loc[0:,'c_lng'],realestate_t.loc[0:,'lat'],realestate_t.loc[0:,'lng'])\n",
    "            # делаем сортировку\n",
    "            realestate_t = realestate_t.sort_values(by = ['distance'], ignore_index = True)\n",
    "            # указываем индекс\n",
    "            realestate_t['sort_id'] = realestate_t.index\n",
    "            # вставляем полученние данные в новую таблицу\n",
    "            df_np = df_np.append(pd.DataFrame(realestate_t.iloc[:5,:], columns = realestate_t.columns))\n",
    "            #df_np = df_np.append(pd.DataFrame(realestate_t.iloc[:,:], columns = realestate_t.columns))\n",
    "            # Очищаем временную\n",
    "            realestate_t = None\n",
    "            avg_sqr = None\n",
    "    # сохраняем в CSV и SQLite\n",
    "    df_np.to_csv(r'\\\\*\\Apps\\Market Rental Rate Report\\csv\\realestate_TOP5_0' + str(q) + '-' + str(y) + '.csv', sep = ';', encoding = 'windows-1251', index = False)\n",
    "    UploadCSV2SQLite ('\\db_MRRP.db', 'DELETE FROM [realestate_top5] WHERE year = ' + str(y) + ' and quarter = ' + str(q),'\\realestate_TOP5_0' + str(q) + '-' + str(y) + '.csv','realestate_top5') #top-5\n",
    "    # очищаем переменные\n",
    "    del ad_csv\n",
    "    del realestate_csv\n",
    "    del df_np\n",
    "    del realestate_t"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edda29fe",
   "metadata": {},
   "source": [
    "Функция для загрузки файлов CSV в SQLite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85ba616e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def UploadCSV2SQLite(lct, del_qr, file, table_sql):\n",
    "    # Подключаемся к БД\n",
    "    lct_cn = r'\\\\*\\Apps\\Market Rental Rate Report\\db' +  lct\n",
    "    ConnectSQLite(lct_cn)\n",
    "    # Очищаем данные перед загрузкой\n",
    "    ExecQuerySQLite(del_qr)\n",
    "    # Отправка файлов\n",
    "    # отправляемый файл\n",
    "    file_v = pd.read_csv(open(r'\\\\*\\Apps\\Market Rental Rate Report\\csv' + file,'r'), sep = ';', decimal = ',')\n",
    "    # отправка\n",
    "    SendDataToSQLite(file_v, table_sql, 'append')\n",
    "    # очищаем переменные\n",
    "    file_v = None\n",
    "    table_v  = None\n",
    "    # Закрытие соединения\n",
    "    DisconnectSQLite()\n",
    "    lct_cn = None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0921d5d",
   "metadata": {},
   "source": [
    "Функция для сохранения файлов CSV в Excel для загрузки в Access и её выполнение"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5ca5c41",
   "metadata": {},
   "outputs": [],
   "source": [
    "#создание функции\n",
    "def SaveForAccess(name_v):\n",
    "    #!Автоматизиовать процесс!\n",
    "    # Сохраняет обработаный файл MRRR_Main из SQLite для загрузки в Access т.к. разнятся кодировки и разделительный символ\n",
    "    ad_csv = pd.read_csv (open(r'\\\\*\\Apps\\Market Rental Rate Report\\csv\\realestate_filtered\\\\' + name_v + '.csv','r'), sep = ';', decimal='.')\n",
    "    writer = pd.ExcelWriter(r'\\\\*\\Apps\\Market Rental Rate Report\\csv\\2access\\\\' + name_v + '.xlsx',engine='xlsxwriter',options={'strings_to_urls': False})\n",
    "    ad_csv.to_excel(writer, sheet_name = name_v, encoding = 'windows-1251', index = False)\n",
    "    writer.save()\n",
    "    ad_csv = None\n",
    "#выполнение\n",
    "files_arr = ['realestate_main','realestate_total','realestate_top5','realestate_ads','realestate_ad','realestate_description']\n",
    "for v in files_arr:\n",
    "    SaveForAccess (v)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7aa3bb1",
   "metadata": {},
   "source": [
    "### Запросы SQL для обработки"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e50bfdd",
   "metadata": {},
   "source": [
    "#### Функции для SQL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5defeeec",
   "metadata": {},
   "outputs": [],
   "source": [
    "cn = None\n",
    "def ConnectSQLite(dbLoc):\n",
    "#Соединение к БД SQLite\n",
    "    try:\n",
    "        global cn\n",
    "        cn = None\n",
    "        cn = sql3.connect(str(dbLoc))\n",
    "    except sql3.Error as error:\n",
    "        print(\"SQLite Error: \", error)\n",
    "    finally:\n",
    "        if (cn):\n",
    "            print(\"Successfully connected!\")\n",
    "\n",
    "def DisconnectSQLite():\n",
    "#Соединение к БД SQLite\n",
    "    try:\n",
    "        global cn\n",
    "        cn.close()\n",
    "        cn = None\n",
    "    except sql3.Error as error:\n",
    "        print(\"SQLite Error: \", error)\n",
    "    finally:\n",
    "        if not (cn):\n",
    "            print(\"Successfull disconnected!\")\n",
    "        \n",
    "def GetDataFromSQLite (qr):\n",
    "#Получение данных из запроса к SQLite\n",
    "    try:\n",
    "        vData = pd.io.sql.read_sql(qr, cn)\n",
    "        return vData\n",
    "    except sql3.Error as error:\n",
    "        print(\"SQLite Error: \", error)\n",
    "    finally:\n",
    "        if (cn):\n",
    "            print(\"Query completed successfully!\")\n",
    "        \n",
    "def ExecQuerySQLite (qr):\n",
    "#Выполнить запрос SQL\n",
    "    try:\n",
    "        cur = cn.cursor()\n",
    "        cur.execute(qr)\n",
    "        cn.commit()\n",
    "    except sql3.Error as error:\n",
    "        print(\"SQLite Error: \", error)\n",
    "    finally:\n",
    "        if (cn):\n",
    "            print(\"Execution query completed successfully!\")\n",
    "            \n",
    "def SendDataToSQLite (dfIn,tabInOut,ifex):\n",
    "#Вставить данные в SQLite из листа Excel с помощью Pandas\n",
    "    try:\n",
    "        err_msg = None\n",
    "        #Вынести отдельно tData = pd.read_excel(pathFile,sheet_name=tabInOut)\n",
    "        dfIn.to_sql(tabInOut, cn, if_exists = ifex, index = False)\n",
    "    except sql3.Error as error:\n",
    "        err_msg = error\n",
    "        print(\"Error: \", err_msg)\n",
    "    finally:\n",
    "        if err_msg == None and (cn):\n",
    "            print(\"Append completed successfully!\")\n",
    "        else:\n",
    "            print(\"Append failed!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
